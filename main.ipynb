{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded libs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import functools\n",
    "import time\n",
    "import config\n",
    "import shutil\n",
    "from my_tools import define_scope\n",
    "import my_tools\n",
    "\n",
    "#To change\n",
    "from my_load_data import load_dataset_fn \n",
    "print(\"loaded libs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "loaded params\n"
     ]
    }
   ],
   "source": [
    "print (len(os.listdir(config.PIC_SRC_DIR)))\n",
    "\n",
    "\n",
    "params = {\"result_dir\": config.RESULT_DIR,\n",
    "          \"learning_rate\": config.LR,\n",
    "          \"img_size\": config.CNN_IN_HEIGHT,\n",
    "          \"num_channels\":config.CNN_IN_CH,\n",
    "          \"num_classes\": config.CNN_OUTPUT_SIZE,\n",
    "          \"batch_size\": config.BATCH_SIZE,\n",
    "          \"total_steps\": 50,\n",
    "          \"keep_probability\": config.KEEP_PROB,\n",
    "          \"print_nth_step\": 10,\n",
    "          \"train_dataset\": os.path.join(config.DATA_DIR,config.TFRECORD_NAMES[0])}\n",
    "print(\"loaded params\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###COMMENTS\n",
    "\"\"\"\n",
    "Accuracy makes softmax of whole tensor\n",
    "\n",
    "Find proper l2 loss function(IOU minimalization)\n",
    "CHANGE DATA PIPELINE!!!!!!\n",
    "get ssh scrypt\n",
    "upload prepared dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TFRECORD STRUCTURE\n",
    "feature = {\"image\" : to_bytes_convert(img.tobytes()),\n",
    "                   \"class\" : to_int_convert(label[0]),\n",
    "                   \"x1\" : to_int_convert(label[1]),\n",
    "                   \"y1\" : to_int_convert(label[2]),\n",
    "                   \"x2\" : to_int_convert(label[3]),\n",
    "                   \"y2\" : to_int_convert(label[4]),\n",
    "                   \"index\" : to_int_convert(index[i])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(serialized_data):\n",
    "    \"\"\"\n",
    "    Decode and map data properly\n",
    "    \"\"\"\n",
    "    \n",
    "    features = {\"image\" : tf.FixedLenFeature((),tf.string),\n",
    "                   \"class\" : tf.FixedLenFeature((),tf.int64),\n",
    "                   \"x1\" : tf.FixedLenFeature((),tf.int64),\n",
    "                   \"y1\" : tf.FixedLenFeature((),tf.int64),\n",
    "                   \"x2\" : tf.FixedLenFeature((),tf.int64),\n",
    "                   \"y2\" : tf.FixedLenFeature((),tf.int64),\n",
    "                   \"index\" : tf.FixedLenFeature((),tf.int64)}\n",
    "    parsed_features = tf.parse_single_example(serialized_data, features)\n",
    "    \n",
    "    image_string = parsed_features[\"image\"]\n",
    "    image = tf.decode_raw(image_string, tf.uint8)\n",
    "    image = tf.cast(image,dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    label = tf.cast((parsed_features[\"class\"], \n",
    "            parsed_features[\"x1\"],\n",
    "            parsed_features[\"y1\"],\n",
    "            parsed_features[\"x2\"],\n",
    "            parsed_features[\"y2\"]), tf.int32)\n",
    "    index = tf.cast(parsed_features[\"index\"], tf.int32)\n",
    "    \n",
    "    return image, label, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRAPPERS FOR MODEL\n",
    "\n",
    "class Model(object):\n",
    "    \"\"\"\n",
    "    Model of NN\n",
    "    \"\"\"\n",
    "    #Variable of model\n",
    "    #accuracy = tf.reduce\n",
    "    \n",
    "    \n",
    "### INITIALIZATION ####    \n",
    "    def __init__(self, params):\n",
    "        #self.permutation = np.random.permutation(range(len(os.listdir(config.PIC_SRC_DIR))))\n",
    "        \n",
    "        self.img_size = params[\"img_size\"]\n",
    "        self.num_channels = params[\"num_channels\"]\n",
    "        self.num_classes = params[\"num_classes\"]\n",
    "        self.lr = params[\"learning_rate\"]\n",
    "        self.keep_prob = params[\"keep_probability\"]\n",
    "        self.write_step = params[\"print_nth_step\"]\n",
    "        self.is_training = False\n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        self.check_mode = 1 # 1 for test ,2 for validation\n",
    "        #remove bellow\n",
    "        self.data = tf.placeholder(dtype= tf.float32, shape=[None,256,256,3])\n",
    "        self.target = tf.placeholder(dtype = tf.int32, shape=[None,5])\n",
    "        self.index = tf.placeholder(dtype= tf.int32,shape=[None,1])\n",
    "        self.permutation = np.random.permutation(range(1,6))\n",
    "        self.data_iter = 1 \n",
    "        self.total_epoch = 0\n",
    "        \n",
    "        #FUNCTIONS, don not remove\n",
    "        self.data_pipeline\n",
    "        self.prediction\n",
    "        self.loss_op\n",
    "        self.optimize\n",
    "        self.summary\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "#FUNCTION DEFINITIONS\n",
    "    @define_scope\n",
    "    def data_pipeline(self):\n",
    "        \"\"\"\n",
    "        loading of TFRecords\n",
    "        \"\"\"\n",
    "        train_dataset = tf.data.TFRecordDataset(params[\"train_dataset\"])\n",
    "        #test_dataset = tf.data.TFRecordDataset(filenames=config.TFRECORD_NAMES[1],num_parallel_reads= 2)\n",
    "        train_dataset =train_dataset.map(parser)\n",
    "        iterator = tf.data.Iterator.from_structure( train_dataset.output_types,\n",
    "                                                    train_dataset.output_shapes)\n",
    "        self.data, self.target, self.index = iterator.get_next()\n",
    "        \n",
    "        \n",
    "        self.data = tf.reshape(self.data,[-1, self.img_size, self.img_size, self.num_channels]) \n",
    "        \n",
    "        self.train_init = iterator.make_initializer(train_dataset)\n",
    "        #test_init = iterator.make_initializer(test_dataset)\n",
    "\n",
    "        \n",
    "   \n",
    " ##### NEURAL NETWORK #####   \n",
    "    @define_scope\n",
    "    def prediction(self, if_training=True):\n",
    "        \"\"\"\n",
    "        Main body of neural network, takes data and labels as input,\n",
    "        returns feature map of photo\n",
    "        \"\"\"\n",
    "    \n",
    "        #1 conv layer\n",
    "        conv1 = tf.layers.conv2d(inputs = self.data, \n",
    "                             filters = 32,\n",
    "                             kernel_size = [5,5],\n",
    "                             strides = 1,\n",
    "                             padding = \"same\",\n",
    "                             activation = tf.nn.relu)\n",
    "        \n",
    "        #1 pool layer, img size reduced by 1/4\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1,\n",
    "                                        pool_size = 2, \n",
    "                                        strides = 2,\n",
    "                                        padding = \"same\")\n",
    "\n",
    "        #2 conv layer\n",
    "        conv2 = tf.layers.conv2d(inputs = pool1, \n",
    "                             filters = 64,\n",
    "                             kernel_size = 5,\n",
    "                             strides = 1,\n",
    "                             padding = \"same\",\n",
    "                             activation = tf.nn.relu)\n",
    "\n",
    "        #2 pool overal image size reduced totaly by factor of 1/16\n",
    "        pool2 = tf.layers.max_pooling2d(inputs = conv2,\n",
    "                                        pool_size = 2, \n",
    "                                        strides = 2,\n",
    "                                        padding = \"same\")\n",
    "        \n",
    "        pool2_flat = tf.reshape(pool2,[-1, 64*64*64])\n",
    "\n",
    "        dense = tf.layers.dense(inputs = pool2_flat,\n",
    "                            units = 128,\n",
    "                            activation = tf.nn.relu)\n",
    "        dropout = tf.layers.dropout(dense,rate = self.keep_prob,training = self.is_training)\n",
    "        \n",
    "        dense2 = tf.layers.dense(inputs = dropout,\n",
    "                             units = self.num_classes,\n",
    "                             activation = tf.nn.relu)\n",
    "       \n",
    "        return tf.nn.softmax(dense2)\n",
    "    \n",
    "    \n",
    "    \n",
    "#### LOSS ####    \n",
    "    @define_scope\n",
    "    def loss_op(self):\n",
    "        \"\"\"\n",
    "        loss\n",
    "        \"\"\"\n",
    "        self.loss = tf.reduce_mean(\n",
    "                    tf.nn.softmax_cross_entropy_with_logits_v2(logits = self.prediction,\n",
    "                                                                labels = self.target))\n",
    "        \n",
    "        return self.loss\n",
    "    \n",
    "    \n",
    "    \n",
    "##### OPTIMIZER #####    \n",
    "    @define_scope    \n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        Optimizer of model\n",
    "        \"\"\"\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.lr)\n",
    "        \n",
    "        return optimizer.minimize(self.loss, global_step=self.global_step)\n",
    "    \n",
    "    \n",
    "    \n",
    "###summary####    \n",
    "    @define_scope\n",
    "    def summary(self):\n",
    "        '''\n",
    "        Create summaries to write on TensorBoard\n",
    "        '''\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "            tf.summary.histogram('histogram_loss', self.loss)\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "            \n",
    "            \n",
    "            \n",
    "#### TRAIN ###        \n",
    "    def train(self, sess, ckpt_dir, writer, saver, step, epoch):\n",
    "        \"\"\"\n",
    "        Training op for model\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        init=self.train_init\n",
    "        sess.run(init)\n",
    "        self.is_training = True\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        self.training = True\n",
    "        try :\n",
    "            while True:\n",
    "                #train\n",
    "                loss, _,summary = sess.run([self.loss_op, self.optimize, self.summary_op])\n",
    "                writer.add_summary(summary, global_step=step)\n",
    "                if (step + 1) % self.write_step == 0:\n",
    "                    print('Loss at step {0}: {1}'.format(step, loss))\n",
    "                    saver.save(sess, ckpt_dir, global_step = step)\n",
    "                step += 1\n",
    "                total_loss += loss\n",
    "                num_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        print('Average loss at epoch {0}: {1}'.format(epoch, total_loss/num_batches))\n",
    "        print('Took: {0} seconds'.format(time.time() - start_time))\n",
    "        \n",
    "        return step\n",
    "    \n",
    "    \n",
    "    \n",
    " #### EVALUATE ####    \n",
    "    def evaluate(self, init, step, epoch):\n",
    "        \"\"\"\n",
    "        Evaluate once from test\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        self.is_training = False\n",
    "        try:\n",
    "            loss, summary = sess.run([self.loss, self.summary_op])\n",
    "            writer.add_summary(summary, global_step=step)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        print('Loss at epoch {0}: {1}'.format(epoch, loss))\n",
    "        print('Took: {0} seconds'.format(time.time() - start_time))\n",
    "        \n",
    "        \n",
    "        \n",
    " ### TO DO ####   \n",
    "    def train_n_times(self, n_times):\n",
    "        pass\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 7\n",
    "def main(remove_results = False):\n",
    "    result_dir = config.RESULT_DIR\n",
    "    \n",
    "    if remove_results == True:\n",
    "        shutil.rmtree(result_dir, ignore_errors=True)\n",
    "    #Check for dirs, if not present make them\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "    ckpt_dir=os.path.join(result_dir,\"ckpt\")\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    #Get name as default graph\n",
    "    with graph.as_default():\n",
    "\n",
    "        print(\"Starting Session\")\n",
    "        #Assign name to session, assign it's default graph as graph\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            \n",
    "            #Creating summary writer \n",
    "            writer = tf.summary.FileWriter(ckpt_dir, graph=graph)\n",
    "                \n",
    "            #Initialization of Model, load all Model functions returning variables\n",
    "            model = Model(params)\n",
    "            \n",
    "            #Assign Initializer\n",
    "            init = tf.global_variables_initializer()\n",
    "            \n",
    "            #Creating save for model session for future saving and restoring model\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            sess.run(init)\n",
    "            #Loading last checkpoint\n",
    "            ckpt = tf.train.get_checkpoint_state(result_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                #if ckpt found load it and load global step\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "                print(\"Found checkpoint\")\n",
    "            step = model.global_step.eval()    \n",
    "                \n",
    "            print(\"we are at step {0}\".format(step))        \n",
    "            #Training\n",
    "            print(\"Starting Training\")\n",
    "\n",
    "            for epoch in range(1,total_epoch):\n",
    "                try: \n",
    "                    step = model.train(sess, ckpt_dir, writer, saver, step, epoch)\n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"keyboard interrupt\")\n",
    "                    step = model.global_step.eval()\n",
    "                    break\n",
    "            #model.global_step = tf.convert_to_tensor(step, dtype=tf.int32)\n",
    "            saver.save(sess, ckpt_dir, global_step = step)\n",
    "            print(model.global_step.eval(), step)\n",
    "        print(\"Finnished session\")\n",
    "        #Merge all summaries\n",
    "        #writer.flush()\n",
    "        writer.add_graph(graph)\n",
    "        writer.close()\n",
    "        print(\"Closed summary, work finnished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Session\n",
      "Initialized Model.data_pipeline\n",
      "Initialized Model.prediction\n",
      "Initialized Model.loss_op\n",
      "Initialized Model.optimize\n",
      "Initialized Model.summary\n",
      "we are at step 0\n",
      "Starting Training\n",
      "Loss at step 9: 687.5054321289062\n",
      "Loss at step 19: 1041.80126953125\n",
      "Loss at step 29: 1248.00341796875\n",
      "Loss at step 39: 877.8466796875\n",
      "Loss at step 49: 848.272705078125\n",
      "Loss at step 59: 931.70166015625\n",
      "Average loss at epoch 1: 890.8946685791016\n",
      "Took: 86.60795378684998 seconds\n",
      "Loss at step 69: 687.5054321289062\n",
      "Loss at step 79: 1041.80126953125\n",
      "Loss at step 89: 1248.00341796875\n",
      "Loss at step 99: 877.8466796875\n",
      "Loss at step 109: 848.272705078125\n",
      "Loss at step 119: 931.70166015625\n",
      "Average loss at epoch 2: 890.8947011311849\n",
      "Took: 77.6024386882782 seconds\n",
      "Loss at step 129: 687.5054321289062\n",
      "Loss at step 139: 1041.80126953125\n",
      "Loss at step 149: 1248.00341796875\n",
      "Loss at step 159: 877.8466796875\n",
      "Loss at step 169: 848.272705078125\n",
      "Loss at step 179: 931.70166015625\n",
      "Average loss at epoch 3: 890.8947011311849\n",
      "Took: 76.15535569190979 seconds\n",
      "Loss at step 189: 687.5054321289062\n",
      "Loss at step 199: 1041.80126953125\n",
      "Loss at step 209: 1248.00341796875\n",
      "Loss at step 219: 877.8466796875\n",
      "Loss at step 229: 848.272705078125\n",
      "Loss at step 239: 931.70166015625\n",
      "Average loss at epoch 4: 890.8947011311849\n",
      "Took: 72.5391492843628 seconds\n",
      "Loss at step 249: 687.5054321289062\n",
      "Loss at step 259: 1041.80126953125\n",
      "Loss at step 269: 1248.00341796875\n",
      "Loss at step 279: 877.8466796875\n",
      "Loss at step 289: 848.272705078125\n",
      "Loss at step 299: 931.70166015625\n",
      "Average loss at epoch 5: 890.8947011311849\n",
      "Took: 63.778647661209106 seconds\n",
      "Loss at step 309: 687.5054321289062\n",
      "Loss at step 319: 1041.80126953125\n",
      "Loss at step 329: 1248.00341796875\n",
      "Loss at step 339: 877.8466796875\n",
      "Loss at step 349: 848.272705078125\n",
      "Loss at step 359: 931.70166015625\n",
      "Average loss at epoch 6: 890.8947011311849\n",
      "Took: 64.04866337776184 seconds\n",
      "360 360\n",
      "Finnished session\n",
      "Closed summary, work finnished\n",
      "Starting Session\n",
      "Initialized Model.data_pipeline\n",
      "Initialized Model.prediction\n",
      "Initialized Model.loss_op\n",
      "Initialized Model.optimize\n",
      "Initialized Model.summary\n",
      "INFO:tensorflow:Restoring parameters from results\\ckpt-360\n",
      "Found checkpoint\n",
      "we are at step 360\n",
      "Starting Training\n",
      "Loss at step 369: 687.5054321289062\n",
      "Loss at step 379: 1041.80126953125\n",
      "Loss at step 389: 1248.00341796875\n",
      "Loss at step 399: 877.8466796875\n",
      "Loss at step 409: 848.272705078125\n",
      "Loss at step 419: 931.70166015625\n",
      "Average loss at epoch 1: 890.8947011311849\n",
      "Took: 81.09063792228699 seconds\n",
      "Loss at step 429: 687.5054321289062\n",
      "Loss at step 439: 1041.80126953125\n",
      "Loss at step 449: 1248.00341796875\n",
      "Loss at step 459: 877.8466796875\n",
      "Loss at step 469: 848.272705078125\n",
      "Loss at step 479: 931.70166015625\n",
      "Average loss at epoch 2: 890.8947011311849\n",
      "Took: 71.53009128570557 seconds\n",
      "Loss at step 489: 687.5054321289062\n",
      "Loss at step 499: 1041.80126953125\n",
      "Loss at step 509: 1248.00341796875\n",
      "Loss at step 519: 877.8466796875\n",
      "Loss at step 529: 848.272705078125\n",
      "Loss at step 539: 931.70166015625\n",
      "Average loss at epoch 3: 890.8947011311849\n",
      "Took: 81.18364381790161 seconds\n",
      "Loss at step 549: 687.5054321289062\n",
      "Loss at step 559: 1041.80126953125\n",
      "Loss at step 569: 1248.00341796875\n",
      "Loss at step 579: 877.8466796875\n",
      "Loss at step 589: 848.272705078125\n",
      "Loss at step 599: 931.70166015625\n",
      "Average loss at epoch 4: 890.8947011311849\n",
      "Took: 79.47754573822021 seconds\n",
      "Loss at step 609: 687.5054321289062\n",
      "Loss at step 619: 1041.80126953125\n",
      "Loss at step 629: 1248.00341796875\n",
      "Loss at step 639: 877.8466796875\n",
      "Loss at step 649: 848.272705078125\n",
      "Loss at step 659: 931.70166015625\n",
      "Average loss at epoch 5: 890.8947011311849\n",
      "Took: 72.90616965293884 seconds\n",
      "Loss at step 669: 687.5054321289062\n",
      "Loss at step 679: 1041.80126953125\n",
      "Loss at step 689: 1248.00341796875\n",
      "Loss at step 699: 877.8466796875\n",
      "Loss at step 709: 848.272705078125\n",
      "Loss at step 719: 931.70166015625\n",
      "Average loss at epoch 6: 890.8947011311849\n",
      "Took: 72.26513338088989 seconds\n",
      "720 720\n",
      "Finnished session\n",
      "Closed summary, work finnished\n"
     ]
    }
   ],
   "source": [
    "### tf.reset_default_graph()\n",
    "if __name__ == '__main__':\n",
    "    check = True\n",
    "    main(remove_results=check)\n",
    "    check = False\n",
    "    main(remove_results=check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tensorboard --logdir=\"results/\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
